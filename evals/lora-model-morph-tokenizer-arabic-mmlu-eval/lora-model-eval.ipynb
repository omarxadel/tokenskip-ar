{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"c9aeac52-d1d3-4c3d-916d-a0d2d153c2ab","cell_type":"code","source":"!pip install git+https://github.com/omarxadel/camel_tools.git\n!camel_data -i all","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T03:47:35.056047Z","iopub.execute_input":"2025-04-08T03:47:35.056415Z","iopub.status.idle":"2025-04-08T03:51:22.355955Z","shell.execute_reply.started":"2025-04-08T03:47:35.056350Z","shell.execute_reply":"2025-04-08T03:51:22.354887Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/omarxadel/camel_tools.git\n  Cloning https://github.com/omarxadel/camel_tools.git to /tmp/pip-req-build-ilamps7o\n  Running command git clone --filter=blob:none --quiet https://github.com/omarxadel/camel_tools.git /tmp/pip-req-build-ilamps7o\n  Resolved https://github.com/omarxadel/camel_tools.git to commit e8e831ed781f2f141a2513e33c8a9c7e5b94554d\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nCollecting camel-kenlm@ git+https://github.com/omarxadel/camel-kenlm.git (from camel_tools==1.5.5)\n  Cloning https://github.com/omarxadel/camel-kenlm.git to /tmp/pip-install-1oq4sonh/camel-kenlm_ad1b3afaeaf544638b5532a1dc725c61\n  Running command git clone --filter=blob:none --quiet https://github.com/omarxadel/camel-kenlm.git /tmp/pip-install-1oq4sonh/camel-kenlm_ad1b3afaeaf544638b5532a1dc725c61\n  Resolved https://github.com/omarxadel/camel-kenlm.git to commit 8c9dcad7263d422c807104e001388d5ece87a203\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from camel_tools==1.5.5) (1.0.0)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from camel_tools==1.5.5) (1.17.0)\nCollecting docopt (from camel_tools==1.5.5)\n  Downloading docopt-0.6.2.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from camel_tools==1.5.5) (5.5.0)\nRequirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from camel_tools==1.5.5) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from camel_tools==1.5.5) (1.13.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from camel_tools==1.5.5) (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from camel_tools==1.5.5) (1.2.2)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from camel_tools==1.5.5) (0.3.8)\nRequirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from camel_tools==1.5.5) (2.5.1+cu121)\nCollecting transformers<4.44.0,>=4.0 (from camel_tools==1.5.5)\n  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from camel_tools==1.5.5) (0.8.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from camel_tools==1.5.5) (2.32.3)\nRequirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from camel_tools==1.5.5) (2.14.1)\nCollecting pyrsistent (from camel_tools==1.5.5)\n  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\nRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from camel_tools==1.5.5) (0.9.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from camel_tools==1.5.5) (4.67.1)\nCollecting muddler (from camel_tools==1.5.5)\n  Downloading muddler-0.1.3-py3-none-any.whl.metadata (7.5 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2->camel_tools==1.5.5) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2->camel_tools==1.5.5) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2->camel_tools==1.5.5) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2->camel_tools==1.5.5) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2->camel_tools==1.5.5) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2->camel_tools==1.5.5) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->camel_tools==1.5.5) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->camel_tools==1.5.5) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->camel_tools==1.5.5) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->camel_tools==1.5.5) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->camel_tools==1.5.5) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->camel_tools==1.5.5) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0->camel_tools==1.5.5) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers<4.44.0,>=4.0->camel_tools==1.5.5) (0.29.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<4.44.0,>=4.0->camel_tools==1.5.5) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.44.0,>=4.0->camel_tools==1.5.5) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.44.0,>=4.0->camel_tools==1.5.5) (2024.11.6)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.44.0,>=4.0->camel_tools==1.5.5) (0.4.5)\nCollecting tokenizers<0.20,>=0.19 (from transformers<4.44.0,>=4.0->camel_tools==1.5.5)\n  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->camel_tools==1.5.5) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->camel_tools==1.5.5) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->camel_tools==1.5.5) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->camel_tools==1.5.5) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->camel_tools==1.5.5) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->camel_tools==1.5.5) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->camel_tools==1.5.5) (2025.1.31)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->camel_tools==1.5.5) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->camel_tools==1.5.5) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->camel_tools==1.5.5) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2->camel_tools==1.5.5) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2->camel_tools==1.5.5) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2->camel_tools==1.5.5) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2->camel_tools==1.5.5) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2->camel_tools==1.5.5) (2024.2.0)\nDownloading transformers-4.43.4-py3-none-any.whl (9.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading muddler-0.1.3-py3-none-any.whl (16 kB)\nDownloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: camel_tools, camel-kenlm, docopt\n  Building wheel for camel_tools (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for camel_tools: filename=camel_tools-1.5.5-py3-none-any.whl size=124605 sha256=10668dc89714d86e78e6fc753926a5abdf2a8d0d5138c92e7c6e1ae13deb4f31\n  Stored in directory: /tmp/pip-ephem-wheel-cache-rl4ofuel/wheels/ed/32/76/d9eb9a693d276ffd1223f043a4e4c1724e3ed3ae4e835fde99\n  Building wheel for camel-kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for camel-kenlm: filename=camel_kenlm-2024.5.6-cp310-cp310-linux_x86_64.whl size=3183053 sha256=b52faad2c6b64759e55bbb0c6ca10468b065f19ce9c4cddfdc6bff2c04d4b673\n  Stored in directory: /tmp/pip-ephem-wheel-cache-rl4ofuel/wheels/f1/59/fe/20c3c4e4a37ff45be44ce4e1e8c2b475e40b95e0b1ead9d774\n  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=92f7748a9c34b015e454cc9d9ddeeb318f015bea976db5df249b66775a7b8311\n  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\nSuccessfully built camel_tools camel-kenlm docopt\nInstalling collected packages: docopt, camel-kenlm, pyrsistent, muddler, tokenizers, transformers, camel_tools\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.0\n    Uninstalling tokenizers-0.21.0:\n      Successfully uninstalled tokenizers-0.21.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\nSuccessfully installed camel-kenlm-2024.5.6 camel_tools-1.5.5 docopt-0.6.2 muddler-0.1.3 pyrsistent-0.20.0 tokenizers-0.19.1 transformers-4.43.4\nThe following packages will be installed: 'disambig-bert-unfactored-egy', 'morphology-db-msa-r13', 'disambig-ranking-cache-calima-egy-r13', 'sentiment-analysis-arabert', 'dialectid-model26', 'morphology-db-msa-s31', 'morphology-db-lev-01', 'ner-arabert', 'disambig-bert-unfactored-lev', 'disambig-mle-calima-egy-r13', 'disambig-bert-unfactored-glf', 'sentiment-analysis-mbert', 'morphology-db-glf-01', 'disambig-ranking-cache-calima-lev-01', 'disambig-ranking-cache-calima-msa-r13', 'disambig-mle-calima-msa-r13', 'disambig-bert-unfactored-msa', 'morphology-db-egy-r13', 'disambig-ranking-cache-calima-glf-01', 'dialectid-model6'\nDownloading package 'disambig-bert-unfactored-egy': 100%|\u001b[32mâ–ˆ\u001b[0m| 446M/446M [00:11<00:\u001b[0m\nExtracting package 'disambig-bert-unfactored-egy': 100%|\u001b[32mâ–ˆ\u001b[0m| 446M/446M [00:00<00:0\u001b[0m\nDownloading package 'morphology-db-msa-r13': 100%|\u001b[32mâ–ˆ\u001b[0m| 40.5M/40.5M [00:00<00:00, 1\u001b[0m\nExtracting package 'morphology-db-msa-r13': 100%|\u001b[32mâ–ˆ\u001b[0m| 40.5M/40.5M [00:00<00:00, 50\u001b[0m\nDownloading package 'disambig-ranking-cache-calima-egy-r13': 100%|\u001b[32mâ–ˆ\u001b[0m| 320M/320M [\u001b[0m\nExtracting package 'disambig-ranking-cache-calima-egy-r13': 100%|\u001b[32mâ–ˆ\u001b[0m| 320M/320M [0\u001b[0m\nDownloading package 'sentiment-analysis-arabert': 100%|\u001b[32mâ–ˆ\u001b[0m| 542M/542M [00:12<00:00\u001b[0m\nExtracting package 'sentiment-analysis-arabert': 100%|\u001b[32mâ–ˆ\u001b[0m| 542M/542M [00:00<00:00,\u001b[0m\nDownloading package 'dialectid-model26': 100%|\u001b[32mâ–ˆ\u001b[0m| 371M/371M [00:08<00:00, 43.0MB/\u001b[0m\nExtracting package 'dialectid-model26': 100%|\u001b[32mâ–ˆ\u001b[0m| 371M/371M [00:00<00:00, 544MB/s]\u001b[0m\nDownloading package 'morphology-db-msa-s31': 100%|\u001b[32mâ–ˆ\u001b[0m| 44.8M/44.8M [00:00<00:00, 4\u001b[0m\nExtracting package 'morphology-db-msa-s31': 100%|\u001b[32mâ–ˆ\u001b[0m| 44.8M/44.8M [00:00<00:00, 51\u001b[0m\nDownloading package 'morphology-db-lev-01': 100%|\u001b[32mâ–ˆ\u001b[0m| 10.6M/10.6M [00:00<00:00, 48\u001b[0m\nExtracting package 'morphology-db-lev-01': 100%|\u001b[32mâ–ˆ\u001b[0m| 10.6M/10.6M [00:00<00:00, 515\u001b[0m\nDownloading package 'ner-arabert': 100%|\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 542M/542M [00:13<00:00, 40.6MB/s]\u001b[0m\nExtracting package 'ner-arabert': 100%|\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 542M/542M [00:00<00:00, 559MB/s]\u001b[0m\nDownloading package 'disambig-bert-unfactored-lev': 100%|\u001b[32mâ–ˆ\u001b[0m| 441M/441M [00:11<00:\u001b[0m\nExtracting package 'disambig-bert-unfactored-lev': 100%|\u001b[32mâ–ˆ\u001b[0m| 441M/441M [00:00<00:0\u001b[0m\nDownloading package 'disambig-mle-calima-egy-r13': 100%|\u001b[32mâ–ˆ\u001b[0m| 27.2M/27.2M [00:00<00\u001b[0m\nExtracting package 'disambig-mle-calima-egy-r13': 100%|\u001b[32mâ–ˆ\u001b[0m| 27.2M/27.2M [00:00<00:\u001b[0m\nDownloading package 'disambig-bert-unfactored-glf': 100%|\u001b[32mâ–ˆ\u001b[0m| 442M/442M [00:11<00:\u001b[0m\nExtracting package 'disambig-bert-unfactored-glf': 100%|\u001b[32mâ–ˆ\u001b[0m| 442M/442M [00:00<00:0\u001b[0m\nDownloading package 'sentiment-analysis-mbert': 100%|\u001b[32mâ–ˆ\u001b[0m| 712M/712M [00:17<00:00, \u001b[0m\nExtracting package 'sentiment-analysis-mbert': 100%|\u001b[32mâ–ˆ\u001b[0m| 712M/712M [00:01<00:00, 5\u001b[0m\nDownloading package 'morphology-db-glf-01': 100%|\u001b[32mâ–ˆ\u001b[0m| 7.98M/7.98M [00:00<00:00, 93\u001b[0m\nExtracting package 'morphology-db-glf-01': 100%|\u001b[32mâ–ˆ\u001b[0m| 7.98M/7.98M [00:00<00:00, 535\u001b[0m\nDownloading package 'disambig-ranking-cache-calima-lev-01': 100%|\u001b[32mâ–ˆ\u001b[0m| 23.2M/23.2M \u001b[0m\nExtracting package 'disambig-ranking-cache-calima-lev-01': 100%|\u001b[32mâ–ˆ\u001b[0m| 23.2M/23.2M [\u001b[0m\nDownloading package 'disambig-ranking-cache-calima-msa-r13': 100%|\u001b[32mâ–ˆ\u001b[0m| 556M/556M [\u001b[0m\nExtracting package 'disambig-ranking-cache-calima-msa-r13': 100%|\u001b[32mâ–ˆ\u001b[0m| 556M/556M [0\u001b[0m\nDownloading package 'disambig-mle-calima-msa-r13': 100%|\u001b[32mâ–ˆ\u001b[0m| 88.7M/88.7M [00:00<00\u001b[0m\nExtracting package 'disambig-mle-calima-msa-r13': 100%|\u001b[32mâ–ˆ\u001b[0m| 88.7M/88.7M [00:00<00:\u001b[0m\nDownloading package 'disambig-bert-unfactored-msa': 100%|\u001b[32mâ–ˆ\u001b[0m| 445M/445M [00:11<00:\u001b[0m\nExtracting package 'disambig-bert-unfactored-msa': 100%|\u001b[32mâ–ˆ\u001b[0m| 445M/445M [00:00<00:0\u001b[0m\nDownloading package 'morphology-db-egy-r13': 100%|\u001b[32mâ–ˆ\u001b[0m| 67.3M/67.3M [00:00<00:00, 1\u001b[0m\nExtracting package 'morphology-db-egy-r13': 100%|\u001b[32mâ–ˆ\u001b[0m| 67.3M/67.3M [00:00<00:00, 54\u001b[0m\nDownloading package 'disambig-ranking-cache-calima-glf-01': 100%|\u001b[32mâ–ˆ\u001b[0m| 28.7M/28.7M \u001b[0m\nExtracting package 'disambig-ranking-cache-calima-glf-01': 100%|\u001b[32mâ–ˆ\u001b[0m| 28.7M/28.7M [\u001b[0m\nDownloading package 'dialectid-model6': 100%|\u001b[32mâ–ˆ\u001b[0m| 153M/153M [00:04<00:00, 33.5MB/s\u001b[0m\nExtracting package 'dialectid-model6': 100%|\u001b[32mâ–ˆâ–ˆ\u001b[0m| 153M/153M [00:00<00:00, 522MB/s]\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"id":"add68505-ca6a-48b2-a0bb-222ca81b5939","cell_type":"code","source":"!pip install unsloth datasets tqdm transformers","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T03:51:22.357170Z","iopub.execute_input":"2025-04-08T03:51:22.357486Z","iopub.status.idle":"2025-04-08T03:54:42.138453Z","shell.execute_reply.started":"2025-04-08T03:51:22.357426Z","shell.execute_reply":"2025-04-08T03:54:42.137392Z"}},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.3.19-py3-none-any.whl.metadata (46 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.43.4)\nCollecting unsloth_zoo>=2025.3.17 (from unsloth)\n  Downloading unsloth_zoo-2025.3.17-py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.5.1+cu121)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nCollecting bitsandbytes (from unsloth)\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.2)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.18-py3-none-any.whl.metadata (9.2 kB)\nCollecting transformers\n  Downloading transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.2.1)\nCollecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth)\n  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.14.0)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.29.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.31.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.20.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nCollecting huggingface_hub (from unsloth)\n  Downloading huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nCollecting tokenizers<0.22,>=0.21 (from transformers)\n  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->unsloth) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (13.9.4)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.3.17->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.3.17->unsloth) (11.0.0)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->unsloth) (8.5.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (4.4.1)\nCollecting typing-extensions>=3.7.4.3 (from huggingface_hub->unsloth)\n  Downloading typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.19.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\nDownloading unsloth-2025.3.19-py3-none-any.whl (192 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m192.7/192.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.51.0-py3-none-any.whl (10.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m481.2/481.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.3.17-py3-none-any.whl (127 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.8/127.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl (43.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.18-py3-none-any.whl (123 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nDownloading typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nInstalling collected packages: triton, nvidia-cusparselt-cu12, typing-extensions, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface_hub, tyro, tokenizers, nvidia-cusolver-cu12, torch, cut_cross_entropy, transformers, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.12.2\n    Uninstalling typing_extensions-4.12.2:\n      Successfully uninstalled typing_extensions-4.12.2\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.29.0\n    Uninstalling huggingface-hub-0.29.0:\n      Successfully uninstalled huggingface-hub-0.29.0\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu121\n    Uninstalling torch-2.5.1+cu121:\n      Successfully uninstalled torch-2.5.1+cu121\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.43.4\n    Uninstalling transformers-4.43.4:\n      Successfully uninstalled transformers-4.43.4\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.20.1+cu121\n    Uninstalling torchvision-0.20.1+cu121:\n      Successfully uninstalled torchvision-0.20.1+cu121\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncamel-tools 1.5.5 requires transformers<4.44.0,>=4.0, but you have transformers 4.51.0 which is incompatible.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\nlangchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\ntorchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.5 cut_cross_entropy-25.1.1 huggingface_hub-0.30.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 shtab-1.7.1 tokenizers-0.21.1 torch-2.6.0 torchvision-0.21.0 transformers-4.51.0 triton-3.2.0 trl-0.15.2 typing-extensions-4.13.1 tyro-0.9.18 unsloth-2025.3.19 unsloth_zoo-2025.3.17 xformers-0.0.29.post3\n","output_type":"stream"}],"execution_count":2},{"id":"8136a570-bff1-491b-98c7-c3b7b1bd6c02","cell_type":"code","source":"import torch\nfrom unsloth import FastLanguageModel\nfrom datasets import load_dataset\nfrom datasets import DatasetDict\nfrom tqdm import tqdm\nimport time\nfrom transformers import GenerationConfig\nimport json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T03:54:42.140060Z","iopub.execute_input":"2025-04-08T03:54:42.140405Z","iopub.status.idle":"2025-04-08T03:55:09.956176Z","shell.execute_reply.started":"2025-04-08T03:54:42.140355Z","shell.execute_reply":"2025-04-08T03:55:09.955243Z"}},"outputs":[{"name":"stdout","text":"ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\nUnsloth: Failed to patch Gemma3ForConditionalGeneration.\nğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":3},{"id":"20f2d92c-85ef-46d7-9af2-76e0af88fadf","cell_type":"code","source":"from camel_tools.morphology.database import MorphologyDB\nfrom camel_tools.morphology.analyzer import Analyzer\nfrom camel_tools.tokenizers.morphological import MorphologicalTokenizer\nfrom camel_tools.disambig.mle import MLEDisambiguator\n\nmle_msa = MLEDisambiguator.pretrained('calima-msa-r13')\nmorph_tokenizer = MorphologicalTokenizer(disambiguator=mle_msa, scheme='atbtok')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:07:55.032907Z","iopub.execute_input":"2025-04-08T04:07:55.033266Z","iopub.status.idle":"2025-04-08T04:07:59.501666Z","shell.execute_reply.started":"2025-04-08T04:07:55.033237Z","shell.execute_reply":"2025-04-08T04:07:59.500948Z"}},"outputs":[],"execution_count":4},{"id":"1a589943-8e99-46ea-a5b8-1ddcad72ff26","cell_type":"code","source":"def load_model(model_name=\"omarxadel/Arabic-Morph-DeepSeek-R1-Distill-Llama-8B\"):\n    \"\"\"Loads the fine-tuned model and tokenizer.\"\"\"\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=model_name,\n        max_seq_length=2048,\n        dtype=None,\n        load_in_4bit=True,\n    )\n    FastLanguageModel.for_inference(model)\n    return model, tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:07:59.502714Z","iopub.execute_input":"2025-04-08T04:07:59.503391Z","iopub.status.idle":"2025-04-08T04:07:59.507425Z","shell.execute_reply.started":"2025-04-08T04:07:59.503344Z","shell.execute_reply":"2025-04-08T04:07:59.506600Z"}},"outputs":[],"execution_count":5},{"id":"150db3dc-056d-449f-a52c-33a85ac7ecd2","cell_type":"code","source":"model, tokenizer = load_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:07:59.508740Z","iopub.execute_input":"2025-04-08T04:07:59.509027Z","iopub.status.idle":"2025-04-08T04:08:46.181402Z","shell.execute_reply.started":"2025-04-08T04:07:59.509005Z","shell.execute_reply":"2025-04-08T04:08:46.180717Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/peft/config.py:162: UserWarning: Unexpected keyword arguments ['alpha_pattern', 'bias', 'corda_config', 'eva_config', 'exclude_modules', 'fan_in_fan_out', 'init_lora_weights', 'layer_replication', 'layers_pattern', 'layers_to_transform', 'loftq_config', 'lora_alpha', 'lora_bias', 'lora_dropout', 'megatron_config', 'megatron_core', 'modules_to_save', 'r', 'rank_pattern', 'target_modules', 'trainable_token_indices', 'use_dora', 'use_rslora'] for class PeftConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.0.\n   \\\\   /|    Tesla P100-PCIE-16GB. Num GPUs = 1. Max memory: 15.888 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 6.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61a1e38f98fa432ebf9a0edb4eacb394"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fda0847ad6034c8c9c3e3d9e45ff1a50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/53.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"829c3880672e42f2b1c8a27c2a29696f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5efe22affa54378bc55dab38afec936"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dca0d25cee84f25a26a275b7bf65484"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/peft/config.py:162: UserWarning: Unexpected keyword arguments ['corda_config', 'trainable_token_indices'] for class LoraConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f46aaa932f1e478792cbbab2f43152cf"}},"metadata":{}},{"name":"stderr","text":"Unsloth 2025.3.19 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}],"execution_count":6},{"id":"6fb62a31-a691-4aab-848f-71c3eace4442","cell_type":"code","source":"# Define a custom tokenizer class\nclass CustomArabicTokenizer:\n    def __init__(self, base_tokenizer, morph_tokenizer):\n        self.base_tokenizer = base_tokenizer\n        self.morph_tokenizer = morph_tokenizer\n\n    def __call__(self, text, **kwargs):\n        # Tokenize using the morphological tokenizer\n        morph_tokens = self.camel_morph_tokenize(text)\n        # Join tokens back into a string\n        morph_text = ' '.join(morph_tokens)\n        # Tokenize using the base tokenizer\n        return self.base_tokenizer(morph_text, **kwargs)\n\n    def camel_morph_tokenize(self, text):\n        words = text.split()  # Split text into words\n        tokenized_words = self.morph_tokenizer.tokenize(words)\n        return tokenized_words\n\n    def tokenize(self, text, **kwargs):\n        # Tokenize using the morphological tokenizer first\n        morph_tokens = self.camel_morph_tokenize(text)\n        morph_text = ' '.join(morph_tokens)\n        # Return token strings from base tokenizer\n        return self.base_tokenizer.tokenize(morph_text, **kwargs)\n\n    def decode(self, token_ids, **kwargs):\n        return self.base_tokenizer.decode(token_ids, **kwargs)\n\n\n# Instantiate the custom tokenizer\ncustom_tokenizer = CustomArabicTokenizer(tokenizer, morph_tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:08:46.182828Z","iopub.execute_input":"2025-04-08T04:08:46.183150Z","iopub.status.idle":"2025-04-08T04:08:46.188465Z","shell.execute_reply.started":"2025-04-08T04:08:46.183118Z","shell.execute_reply":"2025-04-08T04:08:46.187761Z"}},"outputs":[],"execution_count":7},{"id":"078dbd41-f3c9-45c9-b1e6-fd1a61933536","cell_type":"code","source":"def generate_response(model, tokenizer, instruction, options, max_new_tokens=2048):\n    chat_template = \"\"\"Below are some Multiple Choice Questions. Write responses in Arabic language only that appropriately complete each request in a valid, parsable JSON format with two attributes, one will be \"reasoning\" which is your thought process, \n    the other is the \"solution\" that has only a letter (a, b, c or d) in English, which represents the option you chose for the solution based on the options provided in the question.\n\n### Question:\n{INPUT}\n\n### Options:\n{OPTIONS}\n\n### Solution JSON:\n\"\"\"\n    prompt = chat_template.replace(\"{INPUT}\", instruction)\n    prompt = prompt.replace(\"{OPTIONS}\", options)\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    start = time.time()\n    with torch.no_grad():\n        output_ids = model.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n        )\n    end = time.time()\n    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    return output_text, end - start, len(tokenizer.tokenize(output_text))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:08:46.190125Z","iopub.execute_input":"2025-04-08T04:08:46.190321Z","iopub.status.idle":"2025-04-08T04:08:46.211128Z","shell.execute_reply.started":"2025-04-08T04:08:46.190303Z","shell.execute_reply":"2025-04-08T04:08:46.210279Z"}},"outputs":[],"execution_count":8},{"id":"ffad2b9f-f516-446b-8f74-bb522a0c4ede","cell_type":"code","source":"def evaluate(model, tokenizer, dataset, output_path=\"generations.jsonl\", max_samples=5):\n    correct = 0\n    total = 0\n    total_time = 0\n    total_tokens = 0\n\n    with open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n        for example in tqdm(dataset.select(range(max_samples))):\n            question = example[\"Question\"]\n            options = [\n                example[\"Option 1\"],\n                example[\"Option 2\"],\n                example[\"Option 3\"],\n                example[\"Option 4\"],\n            ]\n            answer = example[\"Answer Key\"]\n\n            instruction = f\"{question}\\n\"\n            options_str = \"\"\n            for i, opt in enumerate(options):\n                options_str += f\"{chr(97+i)}. {opt}\\n\"  # a, b, c, d\n\n            response, elapsed_time, token_len = generate_response(model, tokenizer, instruction, options_str)\n            try:\n                response_json = json.loads(response.strip().split(\"### Solution:\")[-1])\n                solution = response_json.get(\"solution\", \"\").lower()\n            except Exception:\n                response_json = None\n                solution = None\n\n            log_entry = {\n                \"id\": example[\"ID\"],\n                \"question\": question,\n                \"options\": {\n                    \"a\": options[0],\n                    \"b\": options[1],\n                    \"c\": options[2],\n                    \"d\": options[3],\n                },\n                \"answer_key\": answer.lower(),\n                \"generated_text\": response,\n            }\n\n            outfile.write(json.dumps(log_entry, ensure_ascii=False) + \"\\n\")\n\n            if solution == answer.lower():\n                correct += 1\n            total += 1\n            total_time += elapsed_time\n            total_tokens += token_len\n\n    print(f\"Accuracy: {correct / total * 100:.2f}%\")\n    print(f\"Average token length: {total_tokens / total:.2f} tokens\")\n    print(f\"Average compute time: {total_time / total:.2f} seconds\")\n    print(f\"Output saved to: {output_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:08:46.212041Z","iopub.execute_input":"2025-04-08T04:08:46.212238Z","iopub.status.idle":"2025-04-08T04:08:46.232038Z","shell.execute_reply.started":"2025-04-08T04:08:46.212220Z","shell.execute_reply":"2025-04-08T04:08:46.231398Z"}},"outputs":[],"execution_count":9},{"id":"f6a75b37-680f-4156-b9bc-566b115d5764","cell_type":"code","source":"ds = load_dataset(\"MBZUAI/ArabicMMLU\", \"All\")[\"dev\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:08:46.232773Z","iopub.execute_input":"2025-04-08T04:08:46.232958Z","iopub.status.idle":"2025-04-08T04:08:59.026677Z","shell.execute_reply.started":"2025-04-08T04:08:46.232940Z","shell.execute_reply":"2025-04-08T04:08:59.026030Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/11.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67e3122f0a9349cc92d4af10aa010276"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.csv:   0%|          | 0.00/6.69M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d82e577f38e74c7c895bfcc2ae3f0f42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev.csv:   0%|          | 0.00/49.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fb61d599f6a4623a862f8f4b2e7eb2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/14455 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"682df61ab3fa4c3f9e25e51f0aedbfd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/120 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28dc469c01bb43b2a86737fdd4dfd2f3"}},"metadata":{}}],"execution_count":10},{"id":"c80061a6-5f98-4616-acb9-dae84a3d6775","cell_type":"code","source":"evaluate(model, custom_tokenizer, ds, max_samples=120)  # Set this higher for full benchmark","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:08:59.027493Z","iopub.execute_input":"2025-04-08T04:08:59.027929Z","iopub.status.idle":"2025-04-08T05:33:52.422890Z","shell.execute_reply.started":"2025-04-08T04:08:59.027894Z","shell.execute_reply":"2025-04-08T05:33:52.421967Z"}},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [1:24:53<00:00, 42.44s/it]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.00%\nAverage token length: 883.77 tokens\nAverage compute time: 42.27 seconds\nOutput saved to: generations.jsonl\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11}]}